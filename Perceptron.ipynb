{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Data Import:**"],"metadata":{"id":"A778DI6lRT9Q"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Load the data from a CSV file\n","data = pd.read_csv(\"data.csv\")\n","display(data)"],"metadata":{"id":"h37zDFqfNg8Y","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1680159178352,"user_tz":-330,"elapsed":500,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"3b0cff84-9a76-4a75-95a1-faea0880b850"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n","0      842302         M        17.99         10.38          122.80     1001.0   \n","1      842517         M        20.57         17.77          132.90     1326.0   \n","2    84300903         M        19.69         21.25          130.00     1203.0   \n","3    84348301         M        11.42         20.38           77.58      386.1   \n","4    84358402         M        20.29         14.34          135.10     1297.0   \n","..        ...       ...          ...           ...             ...        ...   \n","564    926424         M        21.56         22.39          142.00     1479.0   \n","565    926682         M        20.13         28.25          131.20     1261.0   \n","566    926954         M        16.60         28.08          108.30      858.1   \n","567    927241         M        20.60         29.33          140.10     1265.0   \n","568     92751         B         7.76         24.54           47.92      181.0   \n","\n","     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n","0            0.11840           0.27760         0.30010              0.14710   \n","1            0.08474           0.07864         0.08690              0.07017   \n","2            0.10960           0.15990         0.19740              0.12790   \n","3            0.14250           0.28390         0.24140              0.10520   \n","4            0.10030           0.13280         0.19800              0.10430   \n","..               ...               ...             ...                  ...   \n","564          0.11100           0.11590         0.24390              0.13890   \n","565          0.09780           0.10340         0.14400              0.09791   \n","566          0.08455           0.10230         0.09251              0.05302   \n","567          0.11780           0.27700         0.35140              0.15200   \n","568          0.05263           0.04362         0.00000              0.00000   \n","\n","     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n","0    ...        25.380          17.33           184.60      2019.0   \n","1    ...        24.990          23.41           158.80      1956.0   \n","2    ...        23.570          25.53           152.50      1709.0   \n","3    ...        14.910          26.50            98.87       567.7   \n","4    ...        22.540          16.67           152.20      1575.0   \n","..   ...           ...            ...              ...         ...   \n","564  ...        25.450          26.40           166.10      2027.0   \n","565  ...        23.690          38.25           155.00      1731.0   \n","566  ...        18.980          34.12           126.70      1124.0   \n","567  ...        25.740          39.42           184.60      1821.0   \n","568  ...         9.456          30.37            59.16       268.6   \n","\n","     smoothness_worst  compactness_worst  concavity_worst  \\\n","0             0.16220            0.66560           0.7119   \n","1             0.12380            0.18660           0.2416   \n","2             0.14440            0.42450           0.4504   \n","3             0.20980            0.86630           0.6869   \n","4             0.13740            0.20500           0.4000   \n","..                ...                ...              ...   \n","564           0.14100            0.21130           0.4107   \n","565           0.11660            0.19220           0.3215   \n","566           0.11390            0.30940           0.3403   \n","567           0.16500            0.86810           0.9387   \n","568           0.08996            0.06444           0.0000   \n","\n","     concave points_worst  symmetry_worst  fractal_dimension_worst  \n","0                  0.2654          0.4601                  0.11890  \n","1                  0.1860          0.2750                  0.08902  \n","2                  0.2430          0.3613                  0.08758  \n","3                  0.2575          0.6638                  0.17300  \n","4                  0.1625          0.2364                  0.07678  \n","..                    ...             ...                      ...  \n","564                0.2216          0.2060                  0.07115  \n","565                0.1628          0.2572                  0.06637  \n","566                0.1418          0.2218                  0.07820  \n","567                0.2650          0.4087                  0.12400  \n","568                0.0000          0.2871                  0.07039  \n","\n","[569 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-d75f5828-d798-454b-9823-e0f04f5b06e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>...</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>M</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>...</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>...</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>...</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>...</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>...</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>926424</td>\n","      <td>M</td>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>...</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>926682</td>\n","      <td>M</td>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>...</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>926954</td>\n","      <td>M</td>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>...</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>927241</td>\n","      <td>M</td>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>...</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>92751</td>\n","      <td>B</td>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>...</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 32 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d75f5828-d798-454b-9823-e0f04f5b06e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d75f5828-d798-454b-9823-e0f04f5b06e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d75f5828-d798-454b-9823-e0f04f5b06e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["**Feature Engineering Task 1:**"],"metadata":{"id":"7tkPxcFZN-vQ"}},{"cell_type":"code","source":["# Iterate through each column\n","for column in data.columns:\n","    # Check if the column has any missing or zero values\n","    if data[column].isna().sum() + (data[column] == 0).sum() > 0:\n","        # Check if the column is categorical\n","        if data[column].dtype == 'object':\n","            # Impute missing and zero values with the most frequent value\n","            mode_value = data[column].mode()[0]\n","            data[column].fillna(mode_value, inplace=True)\n","            data[column] = data[column].replace(0, mode_value)\n","           # print(\"Column '{}' has been updated. Missing or zero values before: {}. Missing or zero values after: {}. Imputed with value: {}\".format(column, data[column].isna().sum() + (data[column] == 0).sum(), data[column].isna().sum() + (data[column] == 0).sum(), mode_value))\n","        # Otherwise, assume it's a continuous numerical value\n","        else:\n","            # Impute missing and zero values with the mean value\n","            mean_value = data[column].replace(0, np.nan).mean()\n","            data[column].fillna(mean_value, inplace=True)\n","            data[column] = data[column].replace(0, mean_value)\n","          #  print(\"Column '{}' has been updated. Missing or zero values before: {}. Missing or zero values after: {}. Imputed with value: {}\".format(column, data[column].isna().sum() + (data[column] == 0).sum(), data[column].isna().sum() + (data[column] == 0).sum(), mean_value))\n","\n","# Save the updated data to the original CSV file\n","\n","data[\"diagnosis\"] = (data[\"diagnosis\"] ==\"M\").astype(int)\n","data.to_csv(\"data.csv\", index=False)\n","\n","# Print the updated data\n","# print(data[\"diagnosis\"])\n","display(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"-32NUYRYOLMw","executionInfo":{"status":"ok","timestamp":1680159182058,"user_tz":-330,"elapsed":437,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"57299dc4-83a9-4780-f4af-999a90a44a7a"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n","0      842302          1        17.99         10.38          122.80   \n","1      842517          1        20.57         17.77          132.90   \n","2    84300903          1        19.69         21.25          130.00   \n","3    84348301          1        11.42         20.38           77.58   \n","4    84358402          1        20.29         14.34          135.10   \n","..        ...        ...          ...           ...             ...   \n","564    926424          1        21.56         22.39          142.00   \n","565    926682          1        20.13         28.25          131.20   \n","566    926954          1        16.60         28.08          108.30   \n","567    927241          1        20.60         29.33          140.10   \n","568     92751          0         7.76         24.54           47.92   \n","\n","     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n","0       1001.0          0.11840           0.27760        0.300100   \n","1       1326.0          0.08474           0.07864        0.086900   \n","2       1203.0          0.10960           0.15990        0.197400   \n","3        386.1          0.14250           0.28390        0.241400   \n","4       1297.0          0.10030           0.13280        0.198000   \n","..         ...              ...               ...             ...   \n","564     1479.0          0.11100           0.11590        0.243900   \n","565     1261.0          0.09780           0.10340        0.144000   \n","566      858.1          0.08455           0.10230        0.092510   \n","567     1265.0          0.11780           0.27700        0.351400   \n","568      181.0          0.05263           0.04362        0.091008   \n","\n","     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n","0               0.147100  ...        25.380          17.33           184.60   \n","1               0.070170  ...        24.990          23.41           158.80   \n","2               0.127900  ...        23.570          25.53           152.50   \n","3               0.105200  ...        14.910          26.50            98.87   \n","4               0.104300  ...        22.540          16.67           152.20   \n","..                   ...  ...           ...            ...              ...   \n","564             0.138900  ...        25.450          26.40           166.10   \n","565             0.097910  ...        23.690          38.25           155.00   \n","566             0.053020  ...        18.980          34.12           126.70   \n","567             0.152000  ...        25.740          39.42           184.60   \n","568             0.050063  ...         9.456          30.37            59.16   \n","\n","     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n","0        2019.0           0.16220            0.66560         0.711900   \n","1        1956.0           0.12380            0.18660         0.241600   \n","2        1709.0           0.14440            0.42450         0.450400   \n","3         567.7           0.20980            0.86630         0.686900   \n","4        1575.0           0.13740            0.20500         0.400000   \n","..          ...               ...                ...              ...   \n","564      2027.0           0.14100            0.21130         0.410700   \n","565      1731.0           0.11660            0.19220         0.321500   \n","566      1124.0           0.11390            0.30940         0.340300   \n","567      1821.0           0.16500            0.86810         0.938700   \n","568       268.6           0.08996            0.06444         0.278837   \n","\n","     concave points_worst  symmetry_worst  fractal_dimension_worst  \n","0                0.265400          0.4601                  0.11890  \n","1                0.186000          0.2750                  0.08902  \n","2                0.243000          0.3613                  0.08758  \n","3                0.257500          0.6638                  0.17300  \n","4                0.162500          0.2364                  0.07678  \n","..                    ...             ...                      ...  \n","564              0.221600          0.2060                  0.07115  \n","565              0.162800          0.2572                  0.06637  \n","566              0.141800          0.2218                  0.07820  \n","567              0.265000          0.4087                  0.12400  \n","568              0.117286          0.2871                  0.07039  \n","\n","[569 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-23995276-fbdd-4613-8279-085b7f12288a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>...</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>1</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.300100</td>\n","      <td>0.147100</td>\n","      <td>...</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.711900</td>\n","      <td>0.265400</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>1</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.086900</td>\n","      <td>0.070170</td>\n","      <td>...</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.241600</td>\n","      <td>0.186000</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>1</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.197400</td>\n","      <td>0.127900</td>\n","      <td>...</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.450400</td>\n","      <td>0.243000</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>1</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.241400</td>\n","      <td>0.105200</td>\n","      <td>...</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.686900</td>\n","      <td>0.257500</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>1</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.198000</td>\n","      <td>0.104300</td>\n","      <td>...</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.400000</td>\n","      <td>0.162500</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>926424</td>\n","      <td>1</td>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.243900</td>\n","      <td>0.138900</td>\n","      <td>...</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.410700</td>\n","      <td>0.221600</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>926682</td>\n","      <td>1</td>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.144000</td>\n","      <td>0.097910</td>\n","      <td>...</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.321500</td>\n","      <td>0.162800</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>926954</td>\n","      <td>1</td>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.092510</td>\n","      <td>0.053020</td>\n","      <td>...</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.340300</td>\n","      <td>0.141800</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>927241</td>\n","      <td>1</td>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.351400</td>\n","      <td>0.152000</td>\n","      <td>...</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.938700</td>\n","      <td>0.265000</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>92751</td>\n","      <td>0</td>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.091008</td>\n","      <td>0.050063</td>\n","      <td>...</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.278837</td>\n","      <td>0.117286</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 32 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23995276-fbdd-4613-8279-085b7f12288a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-23995276-fbdd-4613-8279-085b7f12288a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-23995276-fbdd-4613-8279-085b7f12288a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["**Feature Engineering Task 2:**"],"metadata":{"id":"JqOvk_qBRTH4"}},{"cell_type":"code","source":["# load the dataset as a Pandas DataFrame\n","df = pd.read_csv('data.csv')\n","# extract the numeric columns except the first two columns and convert to a Numpy array\n","numeric_cols = df.iloc[:, 2:].select_dtypes(include=[np.number]).columns\n","dataset = df[numeric_cols].values\n","\n","# calculate the mean and standard deviation of each feature\n","mu = np.mean(dataset, axis=0)\n","sigma = np.std(dataset, axis=0)\n","\n","# apply feature normalization\n","normalized_dataset = (dataset - mu) / sigma\n","\n","# update the original DataFrame with the normalized values\n","df.loc[:, numeric_cols] = normalized_dataset\n","\n","# save the normalized dataset back to the normData.csv file\n","df.to_csv('normData.csv', index=False)\n","display(df)\n","\n"],"metadata":{"id":"k67BTzfIHQjj","colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"status":"ok","timestamp":1680159212321,"user_tz":-330,"elapsed":5,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"aa9a38b7-13f9-48e2-b7de-9565d1f901e0"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n","0      842302          1     1.103392     -2.073335        1.269505   \n","1      842517          1     1.838251     -0.353632        1.686122   \n","2    84300903          1     1.587601      0.456187        1.566499   \n","3    84348301          1    -0.767935      0.253732       -0.595781   \n","4    84358402          1     1.758499     -1.151816        1.776870   \n","..        ...        ...          ...           ...             ...   \n","564    926424          1     2.120232      0.721473        2.061489   \n","565    926682          1     1.712926      2.085134        1.615998   \n","566    926954          1     0.707480      2.045574        0.671393   \n","567    927241          1     1.846796      2.336457        1.983115   \n","568     92751          0    -1.810409      1.221792       -1.819230   \n","\n","     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n","0     0.984375         1.568466          3.283515    2.666196e+00   \n","1     1.908708        -0.826962         -0.487072   -5.237887e-02   \n","2     1.558884         0.942210          1.052926    1.356639e+00   \n","3    -0.764464         3.283553          3.402909    1.917695e+00   \n","4     1.826229         0.280372          0.539340    1.364289e+00   \n","..         ...              ...               ...             ...   \n","564   2.343856         1.041842          0.219060    1.949574e+00   \n","565   1.723842         0.102458         -0.017833    6.757198e-01   \n","566   0.577953        -0.840484         -0.038680    1.915587e-02   \n","567   1.735218         1.525767          3.272144    3.320337e+00   \n","568  -1.347789        -3.112085         -1.150752   -1.061758e-15   \n","\n","     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n","0           2.550904e+00  ...      1.886690      -1.359293         2.303601   \n","1           5.285732e-01  ...      1.805927      -0.369203         1.535126   \n","2           2.046176e+00  ...      1.511870      -0.023974         1.347475   \n","3           1.449440e+00  ...     -0.281464       0.133984        -0.249939   \n","4           1.425781e+00  ...      1.298575      -1.466770         1.338539   \n","..                   ...  ...           ...            ...              ...   \n","564         2.335343e+00  ...      1.901185       0.117700         1.752563   \n","565         1.257801e+00  ...      1.536720       2.047399         1.421940   \n","566         7.773504e-02  ...      0.561361       1.374854         0.579001   \n","567         2.679715e+00  ...      1.961239       2.237926         2.303601   \n","568        -1.459274e-15  ...     -1.410893       0.764190        -1.432735   \n","\n","     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n","0      2.000417          1.307686           2.616665         2.121444   \n","1      1.889634         -0.375612          -0.430444        -0.182414   \n","2      1.455295          0.527407           1.082932         0.840435   \n","3     -0.551632          3.394275           3.893397         1.998977   \n","4      1.219662          0.220556          -0.313395         0.593540   \n","..          ...               ...                ...              ...   \n","564    2.014484          0.378365          -0.273318         0.645956   \n","565    1.493981         -0.691230          -0.394820         0.208992   \n","566    0.426597         -0.809587           0.350735         0.301088   \n","567    1.652242          1.430427           3.904848         3.232469   \n","568   -1.077587         -1.859019          -1.207552         0.000000   \n","\n","     concave points_worst  symmetry_worst  fractal_dimension_worst  \n","0            2.340123e+00        2.750622                 1.937015  \n","1            1.085646e+00       -0.243890                 0.281190  \n","2            1.986215e+00        1.152255                 0.201391  \n","3            2.215307e+00        6.046041                 4.935010  \n","4            7.143588e-01       -0.868353                -0.397100  \n","..                    ...             ...                      ...  \n","564          1.648107e+00       -1.360158                -0.709091  \n","565          7.190986e-01       -0.531855                -0.973978  \n","566          3.873100e-01       -1.104549                -0.318409  \n","567          2.333803e+00        1.919083                 2.219635  \n","568         -1.096308e-15       -0.048138                -0.751207  \n","\n","[569 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-e681264d-2733-41b5-90fc-e1631212db50\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>...</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>1</td>\n","      <td>1.103392</td>\n","      <td>-2.073335</td>\n","      <td>1.269505</td>\n","      <td>0.984375</td>\n","      <td>1.568466</td>\n","      <td>3.283515</td>\n","      <td>2.666196e+00</td>\n","      <td>2.550904e+00</td>\n","      <td>...</td>\n","      <td>1.886690</td>\n","      <td>-1.359293</td>\n","      <td>2.303601</td>\n","      <td>2.000417</td>\n","      <td>1.307686</td>\n","      <td>2.616665</td>\n","      <td>2.121444</td>\n","      <td>2.340123e+00</td>\n","      <td>2.750622</td>\n","      <td>1.937015</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>1</td>\n","      <td>1.838251</td>\n","      <td>-0.353632</td>\n","      <td>1.686122</td>\n","      <td>1.908708</td>\n","      <td>-0.826962</td>\n","      <td>-0.487072</td>\n","      <td>-5.237887e-02</td>\n","      <td>5.285732e-01</td>\n","      <td>...</td>\n","      <td>1.805927</td>\n","      <td>-0.369203</td>\n","      <td>1.535126</td>\n","      <td>1.889634</td>\n","      <td>-0.375612</td>\n","      <td>-0.430444</td>\n","      <td>-0.182414</td>\n","      <td>1.085646e+00</td>\n","      <td>-0.243890</td>\n","      <td>0.281190</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>1</td>\n","      <td>1.587601</td>\n","      <td>0.456187</td>\n","      <td>1.566499</td>\n","      <td>1.558884</td>\n","      <td>0.942210</td>\n","      <td>1.052926</td>\n","      <td>1.356639e+00</td>\n","      <td>2.046176e+00</td>\n","      <td>...</td>\n","      <td>1.511870</td>\n","      <td>-0.023974</td>\n","      <td>1.347475</td>\n","      <td>1.455295</td>\n","      <td>0.527407</td>\n","      <td>1.082932</td>\n","      <td>0.840435</td>\n","      <td>1.986215e+00</td>\n","      <td>1.152255</td>\n","      <td>0.201391</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>1</td>\n","      <td>-0.767935</td>\n","      <td>0.253732</td>\n","      <td>-0.595781</td>\n","      <td>-0.764464</td>\n","      <td>3.283553</td>\n","      <td>3.402909</td>\n","      <td>1.917695e+00</td>\n","      <td>1.449440e+00</td>\n","      <td>...</td>\n","      <td>-0.281464</td>\n","      <td>0.133984</td>\n","      <td>-0.249939</td>\n","      <td>-0.551632</td>\n","      <td>3.394275</td>\n","      <td>3.893397</td>\n","      <td>1.998977</td>\n","      <td>2.215307e+00</td>\n","      <td>6.046041</td>\n","      <td>4.935010</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>1</td>\n","      <td>1.758499</td>\n","      <td>-1.151816</td>\n","      <td>1.776870</td>\n","      <td>1.826229</td>\n","      <td>0.280372</td>\n","      <td>0.539340</td>\n","      <td>1.364289e+00</td>\n","      <td>1.425781e+00</td>\n","      <td>...</td>\n","      <td>1.298575</td>\n","      <td>-1.466770</td>\n","      <td>1.338539</td>\n","      <td>1.219662</td>\n","      <td>0.220556</td>\n","      <td>-0.313395</td>\n","      <td>0.593540</td>\n","      <td>7.143588e-01</td>\n","      <td>-0.868353</td>\n","      <td>-0.397100</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>926424</td>\n","      <td>1</td>\n","      <td>2.120232</td>\n","      <td>0.721473</td>\n","      <td>2.061489</td>\n","      <td>2.343856</td>\n","      <td>1.041842</td>\n","      <td>0.219060</td>\n","      <td>1.949574e+00</td>\n","      <td>2.335343e+00</td>\n","      <td>...</td>\n","      <td>1.901185</td>\n","      <td>0.117700</td>\n","      <td>1.752563</td>\n","      <td>2.014484</td>\n","      <td>0.378365</td>\n","      <td>-0.273318</td>\n","      <td>0.645956</td>\n","      <td>1.648107e+00</td>\n","      <td>-1.360158</td>\n","      <td>-0.709091</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>926682</td>\n","      <td>1</td>\n","      <td>1.712926</td>\n","      <td>2.085134</td>\n","      <td>1.615998</td>\n","      <td>1.723842</td>\n","      <td>0.102458</td>\n","      <td>-0.017833</td>\n","      <td>6.757198e-01</td>\n","      <td>1.257801e+00</td>\n","      <td>...</td>\n","      <td>1.536720</td>\n","      <td>2.047399</td>\n","      <td>1.421940</td>\n","      <td>1.493981</td>\n","      <td>-0.691230</td>\n","      <td>-0.394820</td>\n","      <td>0.208992</td>\n","      <td>7.190986e-01</td>\n","      <td>-0.531855</td>\n","      <td>-0.973978</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>926954</td>\n","      <td>1</td>\n","      <td>0.707480</td>\n","      <td>2.045574</td>\n","      <td>0.671393</td>\n","      <td>0.577953</td>\n","      <td>-0.840484</td>\n","      <td>-0.038680</td>\n","      <td>1.915587e-02</td>\n","      <td>7.773504e-02</td>\n","      <td>...</td>\n","      <td>0.561361</td>\n","      <td>1.374854</td>\n","      <td>0.579001</td>\n","      <td>0.426597</td>\n","      <td>-0.809587</td>\n","      <td>0.350735</td>\n","      <td>0.301088</td>\n","      <td>3.873100e-01</td>\n","      <td>-1.104549</td>\n","      <td>-0.318409</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>927241</td>\n","      <td>1</td>\n","      <td>1.846796</td>\n","      <td>2.336457</td>\n","      <td>1.983115</td>\n","      <td>1.735218</td>\n","      <td>1.525767</td>\n","      <td>3.272144</td>\n","      <td>3.320337e+00</td>\n","      <td>2.679715e+00</td>\n","      <td>...</td>\n","      <td>1.961239</td>\n","      <td>2.237926</td>\n","      <td>2.303601</td>\n","      <td>1.652242</td>\n","      <td>1.430427</td>\n","      <td>3.904848</td>\n","      <td>3.232469</td>\n","      <td>2.333803e+00</td>\n","      <td>1.919083</td>\n","      <td>2.219635</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>92751</td>\n","      <td>0</td>\n","      <td>-1.810409</td>\n","      <td>1.221792</td>\n","      <td>-1.819230</td>\n","      <td>-1.347789</td>\n","      <td>-3.112085</td>\n","      <td>-1.150752</td>\n","      <td>-1.061758e-15</td>\n","      <td>-1.459274e-15</td>\n","      <td>...</td>\n","      <td>-1.410893</td>\n","      <td>0.764190</td>\n","      <td>-1.432735</td>\n","      <td>-1.077587</td>\n","      <td>-1.859019</td>\n","      <td>-1.207552</td>\n","      <td>0.000000</td>\n","      <td>-1.096308e-15</td>\n","      <td>-0.048138</td>\n","      <td>-0.751207</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 32 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e681264d-2733-41b5-90fc-e1631212db50')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e681264d-2733-41b5-90fc-e1631212db50 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e681264d-2733-41b5-90fc-e1631212db50');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["**Part A - Perceptron Learning Algorithm:**\n"],"metadata":{"id":"46Z9BDbPRi4a"}},{"cell_type":"markdown","source":["***Learning Task 1: ***"],"metadata":{"id":"Wz8zQ_xFRnW_"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","data = pd.read_csv('data.csv')\n","data = data.drop('id', axis=1)  # Drop the id column\n","train_data = data.sample(frac=0.67, random_state=1)  # Randomly select 67% of the data for training\n","test_data = data.drop(train_data.index)  # Use the remaining data for testing\n","class Perceptron:\n","    def __init__(self, input_size, lr=0.01, epochs=50):\n","        self.weights = np.zeros(input_size)\n","        self.lr = lr\n","        self.epochs = epochs\n","\n","    def predict(self, x):\n","        z = np.dot(x, self.weights)\n","        return np.where(z > 0, 1, 0)\n","\n","    def train(self, X, y):\n","        for epoch in range(self.epochs):\n","            for i in range(X.shape[0]):\n","                y_pred = self.predict(X[i])\n","                error = y[i] - y_pred\n","                self.weights += self.lr * error * X[i]\n","def evaluate(model, test_data):\n","    X_test = test_data.iloc[:, 1:].values\n","    y_test = test_data.iloc[:, 0].values\n","    y_pred = model.predict(X_test)\n","    accuracy = np.mean(y_pred == y_test)\n","    return accuracy\n","\n","pm1 = Perceptron(input_size=train_data.shape[1]-1)\n","pm1.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n","pm1_acc = evaluate(pm1, test_data)\n","print(f\"PM1 accuracy: {pm1_acc}\")\n","\n","pm2 = Perceptron(input_size=train_data.shape[1]-1)\n","train_data = train_data.sample(frac=1)  # Shuffle the training data\n","pm2.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n","pm2_acc = evaluate(pm2, test_data)\n","print(f\"PM2 accuracy: {pm2_acc}\")"],"metadata":{"id":"aIPdieyyR4DQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680159302559,"user_tz":-330,"elapsed":1106,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"cc96b0c1-5792-41d7-cd2a-c09ad9056de1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["PM1 accuracy: 0.9202127659574468\n","PM2 accuracy: 0.9361702127659575\n"]}]},{"cell_type":"markdown","source":["Here we have define the perceptron algorithm\n","Then, we have define a function to evaluate the performance of the model on the test set:\n","Now, we can use the perceptron algorithm to train two models (PM1 and PM2) by changing the order of training examples:\n","We can observe that PM1 and PM2 have different accuracies. This is because the order of training examples affects the final weights of the model.\n","\n","\n","\n"],"metadata":{"id":"GfHmKjkHfJKe"}},{"cell_type":"markdown","source":["**Task 2: Building Perceptron Model PM3 on Normalized Data**"],"metadata":{"id":"ZQuDaEz83aS3"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","\n","class Perceptron:\n","    def __init__(self, input_size, lr=0.01, epochs=50):\n","        self.weights = np.zeros(input_size)\n","        self.lr = lr\n","        self.epochs = epochs\n","\n","    def predict(self, x):\n","        z = np.dot(x, self.weights)\n","        return np.where(z > 0, 1, 0)\n","\n","    def train(self, X, y):\n","        for epoch in range(self.epochs):\n","            for i in range(X.shape[0]):\n","                y_pred = self.predict(X[i])\n","                error = y[i] - y_pred\n","                self.weights += self.lr * error * X[i]\n","def evaluate(model, test_data):\n","    X_test = test_data.iloc[:, 1:].values\n","    y_test = test_data.iloc[:, 0].values\n","    y_pred = model.predict(X_test)\n","    accuracy = np.mean(y_pred == y_test)\n","    return accuracy\n","\n","# Load data\n","data = pd.read_csv('normData.csv')\n","data = data.drop('id', axis=1)  # Drop the id column\n","train_data1 = data.sample(frac=0.67, random_state=1)\n","test_data1 = data.drop(train_data.index)\n","\n","# Train PM3 on normalized data\n","pm3 = Perceptron(input_size=train_data1.shape[1]-1)\n","pm3.train(train_data1.iloc[:, 1:].values, train_data1.iloc[:, 0].values)\n","pm3_acc = evaluate(pm3,test_data1)\n","print(f\"PM3 accuracy on normalized data: {pm3_acc}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEh1w_7JiAb4","executionInfo":{"status":"ok","timestamp":1680159345581,"user_tz":-330,"elapsed":394,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"9185f760-cb09-4523-8791-17e08b34e87b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["PM3 accuracy on normalized data: 0.973404255319149\n"]}]},{"cell_type":"markdown","source":["Then, we trained the PM3 model on the normalized training data and evaluated its performance on the normalized testing data. We can observe that PM3 has a different accuracy than PM1 and PM2 due to the normalized data.\n","\n"],"metadata":{"id":"rC2rOwAYfjDC"}},{"cell_type":"markdown","source":["**Task 3: Building Perceptron Model PM4 on Randomly Permutated Features**\n","\n","To build PM4, we will randomly permute the order of features in the dataset:"],"metadata":{"id":"wk_IePPC3o4B"}},{"cell_type":"markdown","source":["Here, we shuffled the columns (features) of the training data using the sample method and then trained the PM4 model on the shuffled training data. We evaluated its performance on the testing data, but only using the features that have non-zero weights in the PM4 model. This is because the weights of the other features were initialized to zero and remained zero throughout the training process. We can observe that PM4 has a different accuracy than PM1, PM2, and PM3 due to the randomly permuted features."],"metadata":{"id":"x8wMOhVAfnnv"}},{"cell_type":"code","source":["\n","import pandas as pd\n","import numpy as np\n","\n","class Perceptron:\n","    def __init__(self, input_size, lr=0.01, epochs=50):\n","        self.weights = np.zeros(input_size)\n","        self.lr = lr\n","        self.epochs =   epochs\n","\n","    def predict(self, x):\n","        z = np.dot(x, self.weights)\n","        return np.where(z > 0, 1, 0)\n","\n","    def train(self, X, y):\n","        for epoch in range(self.epochs):\n","            for i in range(X.shape[0]):\n","                y_pred = self.predict(X[i])\n","                error = y[i] - y_pred\n","                self.weights += self.lr * error * X[i]\n","def evaluate(model, test_data):\n","    X_test = test_data.iloc[:, 1:].values\n","    y_test = test_data.iloc[:, 0].values\n","    y_pred = model.predict(X_test)\n","    accuracy = np.mean(y_pred == y_test)\n","    return accuracy\n","\n","# Load data\n","data = pd.read_csv('data.csv')\n","\n","# Drop id column\n","data = data.drop('id', axis=1)\n","\n","train_data = data.sample(frac=0.67, random_state=1)\n","test_data = data.drop(train_data.index)\n","\n","\n","# Randomly permute feature order\n","np.random.seed(1)\n","perm = np.random.permutation(train_data.shape[1]-1) + 1\n","train_data_permuted = train_data.iloc[:, np.concatenate(([0], perm))]\n","\n","# Train PM4 on permuted data\n","pm4 = Perceptron(input_size=train_data_permuted.shape[1]-1)\n","pm4.train(train_data_permuted.iloc[:, 1:].values, train_data_permuted.iloc[:, 0].values)\n","\n","\n","merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, perm]], axis=1)\n","num_columns1 = data.shape[1]\n","num_columns2 = train_data.shape[1]\n","num_columns3 = test_data.shape[1]\n","\n","# print(\"Number of columns in data :\", num_columns1)\n","# print(\"Number of columns in train data :\", num_columns2)\n","# print(\"Number of columns in test_data :\", num_columns3)\n","\n","num_columns = merged_test_data.shape[1]\n","\n","#print(\"Number of columns in merged data :\", num_columns)\n","\n","merged_test_data.to_csv('test.csv', index=False)\n","\n","pm4_acc = evaluate(pm4, merged_test_data)\n","print(\"PM4 Accuracy:\", pm4_acc)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kS5kbZVQnNMx","executionInfo":{"status":"ok","timestamp":1680159390472,"user_tz":-330,"elapsed":1346,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"f862f63e-6329-44cb-c52b-a4e8ea631e18"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["PM4 Accuracy: 0.9202127659574468\n"]}]},{"cell_type":"markdown","source":["**Accuracy of 10 random samples for PM1**"],"metadata":{"id":"rZmmmgFKeJli"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","class Perceptron:\n","    def __init__(self, input_size, lr=0.01, epochs=50):\n","        self.weights = np.zeros(input_size)\n","        self.lr = lr\n","        self.epochs = epochs\n","\n","    def predict(self, x):\n","        z = np.dot(x, self.weights)\n","        return np.where(z > 0, 1, 0)\n","\n","    def train(self, X, y):\n","        for epoch in range(self.epochs):\n","            for i in range(X.shape[0]):\n","                y_pred = self.predict(X[i])\n","                error = y[i] - y_pred\n","                self.weights += self.lr * error * X[i]\n","def evaluate(model, test_data):\n","    X_test = test_data.iloc[:, 1:].values\n","    y_test = test_data.iloc[:, 0].values\n","    y_pred = model.predict(X_test)\n","    accuracy = np.mean(y_pred == y_test)\n","    return accuracy\n","\n","\n","\n","data = pd.read_csv('data.csv')\n","data = data.drop('id', axis=1)  # Drop the id column\n","\n","\n","\n","accuracies = []\n","for i in range(10):\n","    train_data = data.sample(frac=0.67, random_state=i)  # Randomly select 67% of the data for training\n","    test_data = data.drop(train_data.index)  # Use the remaining data for testing\n","\n","    pm1 = Perceptron(input_size=train_data.shape[1]-1)\n","    pm1.train(train_data.iloc[:, 1:].values, train_data.iloc[:, 0].values)\n","    pm1_acc = evaluate(pm1, test_data)\n","    print(f\"PM1 accuracy: {pm1_acc}\")\n","    accuracies.append(pm1_acc)\n","\n","print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n","print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n"],"metadata":{"id":"2lCsr01PeN4K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680159423414,"user_tz":-330,"elapsed":3493,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"6b01ae13-8f4a-4f16-b0af-edb8b021c558"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["PM1 accuracy: 0.9202127659574468\n","PM1 accuracy: 0.9202127659574468\n","PM1 accuracy: 0.8776595744680851\n","PM1 accuracy: 0.8563829787234043\n","PM1 accuracy: 0.8351063829787234\n","PM1 accuracy: 0.8882978723404256\n","PM1 accuracy: 0.8776595744680851\n","PM1 accuracy: 0.9202127659574468\n","PM1 accuracy: 0.8829787234042553\n","PM1 accuracy: 0.5638297872340425\n","Mean accuracy: 0.85425532\n","Standard deviation: 0.10042350\n"]}]},{"cell_type":"markdown","source":["**Accuracy of 10 random samples for PM3**"],"metadata":{"id":"VegBBuWscgTX"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","\n","class Perceptron:\n","    def __init__(self, input_size, lr=0.01, epochs=50):\n","        self.weights = np.zeros(input_size)\n","        self.lr = lr\n","        self.epochs = epochs\n","\n","    def predict(self, x):\n","        z = np.dot(x, self.weights)\n","        return np.where(z > 0, 1, 0)\n","\n","    def train(self, X, y):\n","        for epoch in range(self.epochs):\n","            for i in range(X.shape[0]):\n","                y_pred = self.predict(X[i])\n","                error = y[i] - y_pred\n","                self.weights += self.lr * error * X[i]\n","def evaluate(model, test_data):\n","    X_test = test_data.iloc[:, 1:].values\n","    y_test = test_data.iloc[:, 0].values\n","    y_pred = model.predict(X_test)\n","    accuracy = np.mean(y_pred == y_test)\n","    return accuracy\n","\n","# Load data\n","data = pd.read_csv('normData.csv')\n","data = data.drop('id', axis=1)  # Drop the id column\n","accuracies = []\n","for i in range(10):\n","    train_data1 = data.sample(frac=0.67, random_state=i)\n","    test_data1 = data.drop(train_data.index)\n","\n","    # Train PM3 on normalized data\n","    pm3 = Perceptron(input_size=train_data1.shape[1]-1)\n","    pm3.train(train_data1.iloc[:, 1:].values, train_data1.iloc[:, 0].values)\n","    pm3_acc = evaluate(pm3,test_data1)\n","    print(pm3_acc)\n","    accuracies.append(pm3_acc)\n","\n","print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n","print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n"],"metadata":{"id":"7P4Nler2cfNa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680159460995,"user_tz":-330,"elapsed":4134,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"fae720e4-93fb-4650-d517-72a255765d9e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9414893617021277\n","0.973404255319149\n","0.9521276595744681\n","0.9840425531914894\n","0.9840425531914894\n","0.9680851063829787\n","0.9680851063829787\n","0.9680851063829787\n","0.9521276595744681\n","0.9574468085106383\n","Mean accuracy: 0.96489362\n","Standard deviation: 0.01328723\n"]}]},{"cell_type":"markdown","source":["**Average accuracy for 10 random samples: PM4**"],"metadata":{"id":"7Hyc0kHYTMBS"}},{"cell_type":"code","source":["\n","import pandas as pd\n","import numpy as np\n","\n","# Load data\n","data = pd.read_csv('data.csv')\n","\n","# Drop id column\n","data = data.drop('id', axis=1)\n","accuracies = []\n","for i in range(10):\n","    # data = data.sample(frac=1)\n","    train_data = data.sample(frac=0.67, random_state=i)\n","    test_data = data.drop(train_data.index)\n","    # split the data into training and testing sets\n","  \n","\n","    # Randomly permute feature order\n","    np.random.seed(1)\n","    perm = np.random.permutation(train_data.shape[1]-1) + 1\n","    train_data_permuted = train_data.iloc[:, np.concatenate(([0], perm))]\n","\n","    # Train PM4 on permuted data\n","    pm4 = Perceptron(input_size=train_data_permuted.shape[1]-1)\n","    pm4.train(train_data_permuted.iloc[:, 1:].values, train_data_permuted.iloc[:, 0].values)\n","\n","\n","    merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, perm]], axis=1)\n","    #merged_test_data = pd.concat([test_data.iloc[:, 0], test_data.iloc[:, np.concatenate(([0], perm))]], axis=1)\n","\n","\n","    pm4_acc = evaluate(pm4, merged_test_data)\n","    print(pm4_acc)\n","    accuracies.append(pm4_acc)\n","\n","print(f\"Mean accuracy: {np.mean(accuracies):.8f}\")\n","print(f\"Standard deviation: {np.std(accuracies):.8f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSE-G0ZPTKAL","executionInfo":{"status":"ok","timestamp":1680159537794,"user_tz":-330,"elapsed":3409,"user":{"displayName":"Satyam Gupta","userId":"14257552402479889297"}},"outputId":"37e8f4be-f949-46c8-f485-54b4291e5813"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9202127659574468\n","0.9202127659574468\n","0.8776595744680851\n","0.8563829787234043\n","0.8351063829787234\n","0.8882978723404256\n","0.8776595744680851\n","0.9202127659574468\n","0.8829787234042553\n","0.5638297872340425\n","Mean accuracy: 0.85425532\n","Standard deviation: 0.10042350\n"]}]}]}